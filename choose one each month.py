# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15mHmpKcKzPc7sH3JBuxt0SS3y3j-Vr7u
"""

# å®‰è£…ä¾èµ–ï¼ˆä»…é¦–æ¬¡è¿è¡Œéœ€è¦ï¼‰
!pip install rasterio matplotlib tqdm

# æŒ‚è½½ Google Driveï¼ˆå¦‚æœåœ¨ Colab ä¸Šè¿è¡Œï¼‰
from google.colab import drive
drive.mount('/content/drive')

# ========= IMPORTS =========
import os
import numpy as np
import rasterio
import matplotlib.pyplot as plt
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
import gc
from datetime import datetime

# ========= è®¾ç½®å‚æ•° =========
# æ ¹ç›®å½•ï¼ˆåŒ…å«7500ä¸ªå­æ–‡ä»¶å¤¹ï¼‰
root_folder = "/content/drive/My Drive/lake100_orignal"
# æ—¥å¿—æ–‡ä»¶è·¯å¾„
log_file_path = os.path.join(root_folder, "processing_log.txt")
# æ¯æ‰¹å¤„ç†å¤šå°‘ä¸ªæ–‡ä»¶å¤¹ï¼ˆå»ºè®® 500â€“1000ï¼‰
batch_size = 1000
# åŒæ—¶å¤„ç†å‡ ä¸ªï¼ˆçº¿ç¨‹æ•°ï¼Œå»ºè®® â‰¤4ï¼‰
max_threads = 3

# ========= åˆå§‹åŒ–æ—¥å¿— =========
with open(log_file_path, "w") as log_file:
    log_file.write(f"ğŸ“˜ ä¸­å€¼åˆæˆå¤„ç†æ—¥å¿— - {datetime.now()}\n\n")

# ========= æŸ¥æ‰¾æ‰€æœ‰å« .tif æ–‡ä»¶çš„å­æ–‡ä»¶å¤¹ =========
all_folders = []
for root, dirs, files in os.walk(root_folder):
    if any(f.endswith(".tif") for f in files):
        all_folders.append(root)

print(f"ğŸ“‚ å…±å‘ç° {len(all_folders)} ä¸ªå¯å¤„ç†çš„å­æ–‡ä»¶å¤¹")

# ========= å•ä¸ªæ–‡ä»¶å¤¹å¤„ç†é€»è¾‘ =========
def process_folder(tif_folder):
    try:
        # è·³è¿‡å·²å¤„ç†çš„
        output_path = os.path.join(tif_folder, "median_composite.png")
        if os.path.exists(output_path):
            return f"âœ… å·²å­˜åœ¨è·³è¿‡: {tif_folder}"

        tif_files = [os.path.join(tif_folder, f) for f in os.listdir(tif_folder) if f.endswith(".tif")]
        if not tif_files:
            return f"âš ï¸ æ—  .tif æ–‡ä»¶è·³è¿‡: {tif_folder}"

        with rasterio.open(tif_files[0]) as src:
            band_count = src.count

        stack = []
        for tif in tif_files:
            with rasterio.open(tif) as src:
                img = src.read().astype(np.float32)
                stack.append(img)

        stack = np.stack(stack, axis=0)
        median_composite = np.median(stack, axis=0)

        rgb = median_composite[:3]
        rgb = rgb / np.max(rgb)
        rgb = np.clip(rgb, 0, 1)
        rgb_img = np.transpose(rgb, (1, 2, 0))

        plt.imsave(output_path, rgb_img)

        # å†…å­˜æ¸…ç†
        del stack, median_composite, rgb, rgb_img
        gc.collect()
        plt.close("all")

        return f"âœ… æˆåŠŸå¤„ç†: {tif_folder}"

    except Exception as e:
        return f"âŒ å¤„ç†å¤±è´¥: {tif_folder}\né”™è¯¯: {str(e)}"

# ========= åˆ†æ‰¹å¹¶è¡Œå¤„ç† =========
def process_in_batches(folders, batch_size=1000, max_threads=3):
    total = len(folders)
    for start in range(0, total, batch_size):
        batch = folders[start:start + batch_size]
        print(f"\nğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {start//batch_size + 1} æ‰¹ï¼ˆå…± {len(batch)} ä¸ªæ–‡ä»¶å¤¹ï¼‰")

        with ThreadPoolExecutor(max_workers=max_threads) as executor, open(log_file_path, "a") as log_file:
            futures = {executor.submit(process_folder, folder): folder for folder in batch}
            for future in tqdm(as_completed(futures), total=len(futures), desc="å¤„ç†è¿›åº¦"):
                result = future.result()
                print(result)
                log_file.write(result + "\n")

# ========= å¯åŠ¨å¤„ç† =========
process_in_batches(all_folders, batch_size=batch_size, max_threads=max_threads)
print(f"\nğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæ¯•ï¼Œæ—¥å¿—ä¿å­˜äºï¼š{log_file_path}")

