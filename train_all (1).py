# -*- coding: utf-8 -*-
"""train_all.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WA7Iz9zK4OdhToo9t8SBCQZr9NiJ1qNe
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
import random

# 你的数据路径（上传后挂载路径）
image_dir = '/content/drive/My Drive/train/img'   # 所有原始图像
mask_dir = '/content/drive/My Drive/train/mask'     # 所有原始掩膜
output_base = '/content/drive/My Drive/dataset/'    # 输出路径
splits = ['train', 'val', 'test']
split_ratio = {'train': 0.7, 'val': 0.1, 'test': 0.2}

# 创建输出结构
for split in splits:
    os.makedirs(os.path.join(output_base, split, 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_base, split, 'masks'), exist_ok=True)

# 收集所有图像文件名
all_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])
random.shuffle(all_files)
total = len(all_files)

# 划分
train_end = int(split_ratio['train'] * total)
val_end = train_end + int(split_ratio['val'] * total)

split_files = {
    'train': all_files[:train_end],
    'val': all_files[train_end:val_end],
    'test': all_files[val_end:]
}

# 复制文件到新目录
for split, files in split_files.items():
    for f in files:
        img_src = os.path.join(image_dir, f)
        mask_name = f.replace('.jpg', '.png').replace('.jpeg', '.png')
        mask_src = os.path.join(mask_dir, mask_name)

        shutil.copy(img_src, os.path.join(output_base, split, 'images', f))
        shutil.copy(mask_src, os.path.join(output_base, split, 'masks', mask_name))

print("数据划分完成，共计：")
for k, v in split_files.items():
    print(f"{k}: {len(v)} 张图")

# =============================================
# 🧠 第二步：训练 U-Net 模型（train_unet.py）
# =============================================
import numpy as np
import tensorflow as tf
import cv2
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
import glob
from tqdm import tqdm

# 读取训练图像和掩膜
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path = '/content/drive/My Drive/dataset/val/images/'
val_mask_path = '/content/drive/My Drive/dataset/val/masks/'

def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        img = cv2.resize(img, img_size)
        img = img / 255.0

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, img_size)
        mask = (mask > 127).astype(np.float32)

        images.append(img)
        masks.append(mask)

    return np.array(images), np.array(masks).reshape(-1, img_size[0], img_size[1], 1)

x_train, y_train = load_data(train_img_path, train_mask_path)
x_val, y_val = load_data(val_img_path, val_mask_path)

# 构建 U-Net 模型
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    def conv_block(x, filters):
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        return x

    c1 = conv_block(inputs, 64)
    p1 = MaxPooling2D()(c1)
    c2 = conv_block(p1, 128)
    p2 = MaxPooling2D()(c2)
    c3 = conv_block(p2, 256)
    p3 = MaxPooling2D()(c3)
    c4 = conv_block(p3, 512)
    p4 = MaxPooling2D()(c4)
    c5 = conv_block(p4, 1024)

    u6 = Conv2DTranspose(512, 2, strides=2, padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = conv_block(u6, 512)

    u7 = Conv2DTranspose(256, 2, strides=2, padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = conv_block(u7, 256)

    u8 = Conv2DTranspose(128, 2, strides=2, padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = conv_block(u8, 128)

    u9 = Conv2DTranspose(64, 2, strides=2, padding='same')(c8)
    u9 = concatenate([u9, c1])
    c9 = conv_block(u9, 64)

    outputs = Conv2D(1, 1, activation='sigmoid')(c9)

    model = Model(inputs, outputs)
    return model

model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 训练模型
model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=8, epochs=20)

# 保存模型
model.save('/content/drive/My Drive/unet_model.h5')

# 🧠 第三步：训练 SegNet 模型（train_segnet.py）
# =============================================
import numpy as np
import tensorflow as tf
import cv2
import glob
from tqdm import tqdm
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, BatchNormalization, Activation, Dense, Reshape
from tensorflow.keras.models import Model

train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path = '/content/drive/My Drive/dataset/val/images/'
val_mask_path = '/content/drive/My Drive/dataset/val/masks/'

def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(img_dir + '*'))
    for img_path in tqdm(img_files):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        img = cv2.resize(img, img_size)
        img = img / 255.0

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, img_size)
        mask = (mask > 127).astype(np.float32)

        images.append(img)
        masks.append(mask)

    return np.array(images), np.array(masks).reshape(-1, img_size[0], img_size[1], 1)

x_train, y_train = load_data(train_img_path, train_mask_path)
x_val, y_val = load_data(val_img_path, val_mask_path)

# 构建 SegNet 模型
def build_segnet(input_shape=(256, 256, 3)):
    inputs = Input(shape=input_shape)

    # Encoder
    x = Conv2D(64, (3,3), padding='same')(inputs)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(128, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(256, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    # Decoder
    x = UpSampling2D()(x)
    x = Conv2DTranspose(256, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(128, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(64, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = Conv2DTranspose(1, (1,1), activation='sigmoid')(x)

    return Model(inputs, x)

segnet = build_segnet()
segnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 训练模型
segnet.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=8, epochs=20)

# 保存模型
segnet.save('/content/drive/My Drive/segnet_model.h5')

# =============================================
# 🧠 第四步：训练 FCN 模型（train_fcn.py）
# =============================================
import numpy as np
import tensorflow as tf
import cv2
import glob
from tqdm import tqdm
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Add, Activation
from tensorflow.keras.models import Model

train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path = '/content/drive/My Drive/dataset/val/images/'
val_mask_path = '/content/drive/My Drive/dataset/val/masks/'

def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(img_dir + '*'))
    for img_path in tqdm(img_files):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        img = cv2.resize(img, img_size)
        img = img / 255.0

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, img_size)
        mask = (mask > 127).astype(np.float32)

        images.append(img)
        masks.append(mask)

    return np.array(images), np.array(masks).reshape(-1, img_size[0], img_size[1], 1)

x_train, y_train = load_data(train_img_path, train_mask_path)
x_val, y_val = load_data(val_img_path, val_mask_path)

# 构建 FCN 模型（基于 VGG16）
def build_fcn(input_shape=(256, 256, 3)):
    vgg = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)
    for layer in vgg.layers: layer.trainable = False

    f3 = vgg.get_layer('block3_pool').output
    f4 = vgg.get_layer('block4_pool').output
    f5 = vgg.get_layer('block5_pool').output

    o = Conv2D(512, (7, 7), activation='relu', padding='same')(f5)
    o = Conv2D(512, (1, 1), activation='relu', padding='same')(o)
    o = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(o)

    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same')(o)
    o2 = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(f4)
    o = Add()([o, o2])

    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same')(o)
    o3 = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(f3)
    o = Add()([o, o3])

    o = Conv2DTranspose(1, kernel_size=(8, 8), strides=(8, 8), padding='same')(o)
    o = Activation('sigmoid')(o)

    model = Model(inputs=vgg.input, outputs=o)
    return model

fcn = build_fcn()
fcn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 训练 FCN 模型
fcn.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=8, epochs=20)

# 保存模型
fcn.save('/content/drive/My Drive/fcn_model.h5')