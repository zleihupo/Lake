# -*- coding: utf-8 -*-
"""train_all.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WA7Iz9zK4OdhToo9t8SBCQZr9NiJ1qNe
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
import random

# ä½ çš„æ•°æ®è·¯å¾„ï¼ˆä¸Šä¼ åæŒ‚è½½è·¯å¾„ï¼‰
image_dir = '/content/drive/My Drive/train/img'   # æ‰€æœ‰åŸå§‹å›¾åƒ
mask_dir = '/content/drive/My Drive/train/mask'     # æ‰€æœ‰åŸå§‹æ©è†œ
output_base = '/content/drive/My Drive/dataset/'    # è¾“å‡ºè·¯å¾„
splits = ['train', 'val', 'test']
split_ratio = {'train': 0.7, 'val': 0.1, 'test': 0.2}

# åˆ›å»ºè¾“å‡ºç»“æ„
for split in splits:
    os.makedirs(os.path.join(output_base, split, 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_base, split, 'masks'), exist_ok=True)

# æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶å
all_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])
random.shuffle(all_files)
total = len(all_files)

# åˆ’åˆ†
train_end = int(split_ratio['train'] * total)
val_end = train_end + int(split_ratio['val'] * total)

split_files = {
    'train': all_files[:train_end],
    'val': all_files[train_end:val_end],
    'test': all_files[val_end:]
}

# å¤åˆ¶æ–‡ä»¶åˆ°æ–°ç›®å½•
for split, files in split_files.items():
    for f in files:
        img_src = os.path.join(image_dir, f)
        mask_name = f.replace('.jpg', '.png').replace('.jpeg', '.png')
        mask_src = os.path.join(mask_dir, mask_name)

        shutil.copy(img_src, os.path.join(output_base, split, 'images', f))
        shutil.copy(mask_src, os.path.join(output_base, split, 'masks', mask_name))

print("æ•°æ®åˆ’åˆ†å®Œæˆï¼Œå…±è®¡ï¼š")
for k, v in split_files.items():
    print(f"{k}: {len(v)} å¼ å›¾")

# =============================================
# ğŸ§  ç¬¬äºŒæ­¥ï¼šè®­ç»ƒ U-Net æ¨¡å‹ï¼ˆtrain_unet.pyï¼‰
# =============================================
import numpy as np
import tensorflow as tf
import cv2
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
import glob
from tqdm import tqdm

# è¯»å–è®­ç»ƒå›¾åƒå’Œæ©è†œ
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path = '/content/drive/My Drive/dataset/val/images/'
val_mask_path = '/content/drive/My Drive/dataset/val/masks/'

def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        img = cv2.resize(img, img_size)
        img = img / 255.0

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, img_size)
        mask = (mask > 127).astype(np.float32)

        images.append(img)
        masks.append(mask)

    return np.array(images), np.array(masks).reshape(-1, img_size[0], img_size[1], 1)

x_train, y_train = load_data(train_img_path, train_mask_path)
x_val, y_val = load_data(val_img_path, val_mask_path)

# æ„å»º U-Net æ¨¡å‹
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    def conv_block(x, filters):
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        return x

    c1 = conv_block(inputs, 64)
    p1 = MaxPooling2D()(c1)
    c2 = conv_block(p1, 128)
    p2 = MaxPooling2D()(c2)
    c3 = conv_block(p2, 256)
    p3 = MaxPooling2D()(c3)
    c4 = conv_block(p3, 512)
    p4 = MaxPooling2D()(c4)
    c5 = conv_block(p4, 1024)

    u6 = Conv2DTranspose(512, 2, strides=2, padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = conv_block(u6, 512)

    u7 = Conv2DTranspose(256, 2, strides=2, padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = conv_block(u7, 256)

    u8 = Conv2DTranspose(128, 2, strides=2, padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = conv_block(u8, 128)

    u9 = Conv2DTranspose(64, 2, strides=2, padding='same')(c8)
    u9 = concatenate([u9, c1])
    c9 = conv_block(u9, 64)

    outputs = Conv2D(1, 1, activation='sigmoid')(c9)

    model = Model(inputs, outputs)
    return model

model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# è®­ç»ƒæ¨¡å‹
model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=8, epochs=20)

# ä¿å­˜æ¨¡å‹
model.save('/content/drive/My Drive/unet_model.h5')

# ğŸ§  ç¬¬ä¸‰æ­¥ï¼šè®­ç»ƒ SegNet æ¨¡å‹ï¼ˆtrain_segnet.pyï¼‰
# =============================================
import numpy as np
import tensorflow as tf
import cv2
import glob
from tqdm import tqdm
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, BatchNormalization, Activation, Dense, Reshape
from tensorflow.keras.models import Model

train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path = '/content/drive/My Drive/dataset/val/images/'
val_mask_path = '/content/drive/My Drive/dataset/val/masks/'

def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(img_dir + '*'))
    for img_path in tqdm(img_files):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        img = cv2.resize(img, img_size)
        img = img / 255.0

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, img_size)
        mask = (mask > 127).astype(np.float32)

        images.append(img)
        masks.append(mask)

    return np.array(images), np.array(masks).reshape(-1, img_size[0], img_size[1], 1)

x_train, y_train = load_data(train_img_path, train_mask_path)
x_val, y_val = load_data(val_img_path, val_mask_path)

# æ„å»º SegNet æ¨¡å‹
def build_segnet(input_shape=(256, 256, 3)):
    inputs = Input(shape=input_shape)

    # Encoder
    x = Conv2D(64, (3,3), padding='same')(inputs)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(128, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(256, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    # Decoder
    x = UpSampling2D()(x)
    x = Conv2DTranspose(256, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(128, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(64, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = Conv2DTranspose(1, (1,1), activation='sigmoid')(x)

    return Model(inputs, x)

segnet = build_segnet()
segnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# è®­ç»ƒæ¨¡å‹
segnet.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=8, epochs=20)

# ä¿å­˜æ¨¡å‹
segnet.save('/content/drive/My Drive/segnet_model.h5')

# =============================================
# ğŸ§  ç¬¬å››æ­¥ï¼šè®­ç»ƒ FCN æ¨¡å‹ï¼ˆtrain_fcn.pyï¼‰
# =============================================
import numpy as np
import tensorflow as tf
import cv2
import glob
from tqdm import tqdm
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Add, Activation
from tensorflow.keras.models import Model

train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path = '/content/drive/My Drive/dataset/val/images/'
val_mask_path = '/content/drive/My Drive/dataset/val/masks/'

def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(img_dir + '*'))
    for img_path in tqdm(img_files):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        img = cv2.resize(img, img_size)
        img = img / 255.0

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, img_size)
        mask = (mask > 127).astype(np.float32)

        images.append(img)
        masks.append(mask)

    return np.array(images), np.array(masks).reshape(-1, img_size[0], img_size[1], 1)

x_train, y_train = load_data(train_img_path, train_mask_path)
x_val, y_val = load_data(val_img_path, val_mask_path)

# æ„å»º FCN æ¨¡å‹ï¼ˆåŸºäº VGG16ï¼‰
def build_fcn(input_shape=(256, 256, 3)):
    vgg = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)
    for layer in vgg.layers: layer.trainable = False

    f3 = vgg.get_layer('block3_pool').output
    f4 = vgg.get_layer('block4_pool').output
    f5 = vgg.get_layer('block5_pool').output

    o = Conv2D(512, (7, 7), activation='relu', padding='same')(f5)
    o = Conv2D(512, (1, 1), activation='relu', padding='same')(o)
    o = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(o)

    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same')(o)
    o2 = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(f4)
    o = Add()([o, o2])

    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same')(o)
    o3 = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(f3)
    o = Add()([o, o3])

    o = Conv2DTranspose(1, kernel_size=(8, 8), strides=(8, 8), padding='same')(o)
    o = Activation('sigmoid')(o)

    model = Model(inputs=vgg.input, outputs=o)
    return model

fcn = build_fcn()
fcn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# è®­ç»ƒ FCN æ¨¡å‹
fcn.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=8, epochs=20)

# ä¿å­˜æ¨¡å‹
fcn.save('/content/drive/My Drive/fcn_model.h5')